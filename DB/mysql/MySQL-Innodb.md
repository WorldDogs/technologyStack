# MySQL-Innodb

本文主要整理MySQL服务端，以及Innodb引擎

## Innodb

### 表的存储

- 根据主键的顺序以索引的形式存放，被称为索引组织表（结构上是b+树）

## MySQL架构

### 

- 子主题 1

### 职责划分

- 连接器

	- 用途

		- 负责维护server和客户端的连接，鉴权

			- 建立连接的流程

			  tcp三次握手，发起鉴权请求，连接器会去查询这个用户的权限，并缓存再内存中，所以如果修改了权限没有断开连接，权限没有刷新。

	- 常见问题

		- 长连接

		  mysql的临时申请内存保存在连接对象中，只有在连接断开才会释放，如果保持时间过长，会累计，最终导致mysql崩溃重启

			- 解决方案

				- mysql_reset_connection

				  并不会重新建立连接，会让连接状态变到连接刚建立状态

- 查询缓存

	- mysql8.0已经彻底移除这个模块

		- 子主题 1

	- 用途

		- 会建立 查询-结果 的key-value对，命中后直接返回

	- 存在的问题

		- 党对一个表进行更新后(不限于修改表结构)，此表的缓存会全部清空。

- 分析器

	- 用途

		- 此阶段会分析你操作的表以及数据等，并确定你的语法是否有问题

			- 词法分析
			- 语法分析

- 优化器

	- 用途

		- 当存在多个索引或者join时，mysql会判断用哪些索引，以及表如何进行更高效的连接

- 执行器

	- 用途

		- 会调用存储引擎的读写接口，当进行修改操作时，将数据读出来，在执行器中将数据进行修改，然后调用存储引擎的写入接口将结果写回存储引擎

### 日志系统

- binlog

	- 定义

		- 由mysql 服务层提供

- redo log

	- 定义

		- 由存储引擎提供，时innodb独有的

## 命令

### 查看连接

- show processlist

## 索引

### 定义

- 用途

	- 提高数据的检索速度

- 每一个索引都是一个b+树
- 是由存储引擎层实现

### 索引使用原则

### 无法使用索引的情况

- 对索引字段进行了函数计算

  除了最直接的最索引字段进行函数操作，
  隐式字段转换、隐式字符集转换也可能会对索引字段进行隐式的函数调用，导致无法使用索引，走了全表扫描

	- 字段进行了函数操作，无法使用索引

		- 原理

			- 我们是对对应的字段简历了索引，但是函数操作后会变成其他的值，是找不到的。

				- 

		- 实践

			- where id+1=?

				- 不会使用索引

			- where id=?-1

				- 会使用索引

	- 隐式字符编码转换

		- 当两个表中关联字段字符集不一样，就会发生隐式类型转换，如果被转换的为索引字段，自然无法走索引

	- 隐式类型转换

		- 当字符串和数字做比较时，字符串会转换成数字，如果查询字段被转换，就无法使用索引

### 由来

- 思考过程

	- 用于提高检索速度的数据结构

		- hash

			- 等值查询很快，不适用范围查询

		- 有序数组

			- 可以用二分来查，但是只适合静态数据

		- 二叉树

			- log级别查询，但是如果数据量大，要读多个节点，对于磁盘io损耗大

		- n叉树

			- log级别，如果一个节点存储更多数据，那么层数就会减小，访问磁盘的次数就会减少

### 例子

- 

	- 索引的叶子节点是页(page)，page中包含多条记录。那在页中如何定位数据呢，

		- 1页

			- 1槽

				- 1组

					- n调记录

			- 2槽
			- 。。。
			- n槽

		- 页内二分定槽，即定组，组内遍历链表定记录

- 表结构

	- 

- 数据

	- （id,k）=>(100,1),(200,2),(300,3),(500,5),(600,6)

- 查询

	- select * from T where id=500

		- 主键查询方式，查的是主键索引

	- select * from T where k=1

		- 非主键索引查询方式，查的是k列对应的索引，查到id=100后还需要去主键索引查一次，这种情况也被称为：回表

- 插入

	- 如果插入id=700,那么只需要插入到id=600后面(id=600行所在节点中)
	- 如果插入id=400,则需要挪动数据，空出位置！(如果所在的数据页满了，则需要申请新的数据页，并挪动数据，这种情况称为：叶分裂，页合并发生在页的利用率很低时【删除了数据】，页合并是和页分裂相反的过程)

### 主键索引

- 主键索引叶子存放整行数据，也被称为：聚簇索引

### 非主键索引

- 叶子存放主键值，也被称为：二级索引

### 联合索引｜多列索引

- 定义:用多个列创建索引b+树
- 最左前缀原则

	- 匹配原则为从左到右匹配，如果匹配到三个那就只能用三个

- 

### 索引覆盖

- 定义

	- 是指覆盖了我们的查询要求，比如说要查a,b,c三列，恰好都在这个联合索引里面，这种情况称为索引覆盖

- 优点

	- 非主键索引查询，最终查到的是主键索引值，然后回到主键索引中查对应的行，这就会造成回表，降低查询性能。

### 索引下推

- 假设：key(name,age) 查姓张并且年龄为10的记录，5.6之前不会在索引中判断age的值，需要回表取记录再做比较，而5.6之后，会直接判断age，如果age不符合就会跳过，这种过程被称为：索引下推

### 普通索引和唯一索引的区别

- 普通索引定位到行后还需要继续向下查，直到有一个不匹配
- 唯一索引，由于命中之后只有一个记录，所以不会继续向下搜索，但是这两者的性能差距是微乎其微的(原因是当需要读一条记录时，会将整个数据页读进内存)
- 执行机制区别

	- 对于普通索引，存在一块changebuffer的内存(目的是加快更新操作的速度，由于唯一索引每次执行更新操作都必须判断唯一性，需要进入数据库里面查，所以没有changebuffer。而对于普通索引的数据行更新操作，会先去判断数据行在不在内存中，如果存在内存中直接更新，如果不存在内存中则会将更新操作写入changebuffer，那写入changebuffer中的数据如何更新到数据库中的呢，请看merge执行时机)。
	- merge

		- merge就是将changebuffer中某些内容应用到数据页，或者直接写回磁盘  
		- merge执行时机

			- 后台系统线程定期的将changebuffer中的操作，写回磁盘
			- 当和changebuffer相关的数据读入内存中的时候，也会触发merge，更新读到的数据，此时内存中的数据就成了脏页，就会走脏页流程

- 实践

	- 普通索引很适合，写多读少的场景，例如log表，账单表，在merge之前changebuffer中积累的数据越多收益就会越大(减少了很多的磁盘随机IO)，相反对于极端情况:写后立刻进行读操作，这会立刻出发merge操作，增加了changebffer的维护成本

### 优化器-索引选择

- 优化器选择索引的判断条件

	- 扫描行数
	- 临时表
	- 排序

- 索引统计

	- 优化器基于统计来估算将要执行操作的代价

		- 子主题 1

	- 存储

		- 索引统计存储在【内存｜持久化存储】

	- 

		- cardinality-基数

		  表示索引的区分度，一个索引上的不同的值越多区分度越大
		  由于不可能扫描所有的数据，所以统计的方式是选取一定的数据页，然后统计数据页的数据，最后乘以数据页数量，得到基数

	- 修复统计信息错误

		- analyze table t

			- ；此命令重新统计索引信息

### 字符串索引

- 前缀索引

	- key(a(6)) 只选择前6个字符
	- 优点

		- 减小索引大小

	- 缺点

		- 无法使用覆盖索引，即使覆盖了长度，但是mysql并不知道是不是覆盖了，仍需要回表
		- 需要有一个命中预期，比如说key(a(6)),六个字符会命中95%的值，你的预期低于95%那是可以的

	- 实践

		- 对于身份证这一类，前缀命中率低，可以使用倒叙存放

## 锁

### 锁的用途

- 数据库可能是多个client在操作同一份数据，就会出现并发访问问题，mysql通过锁来解决这个问题。

### 全局锁

- 对整个数据库加锁

	- 让整个数据库只读,

		- flush tables with read lock
		- set global readonly=true
		- 区别

			- 如果客户端执行第一个后，发生异常断开，锁会被自动释放，但是第二种不会！

### 表锁

- 表锁

	- 命令

		- lock tables ... read/write
		- unlock tables...

	- 客户端断开后会自动释放，除了会限制其他线程读写，也会限制本线程
	- 读锁

		- 可以读

	- 写锁

		- 读写都不可

- 元数据锁(meta data lock,MDL)

	- 场景

		- 一个连接在读表，另一个连接删除了这个表的一个列，读出来的数据就会不一致

	- 运作机制

		- 不需要显示使用，在访问表时会自动加上。
		- 对表左curd时，加MDL读锁。表结构变更时加MDL写锁，读锁不互斥，多个线程可以对同一个表增删改查。读写，写写锁直接互斥，需要等待锁释放。
		- MDL在事务执行时申请，在提交后才会释放

	- 引入版本：5.5
	- 使用不当引发的问题

		- 假设有：a,b,c,d四个事务，且书写顺序也为事务开始时间顺序，a,b为读，c要改表结构，d为读，a申请后一直没有提交，b读没问题，c来了会被阻塞，d由于c在排队的缘故也会阻塞。同样只要c的锁不释放(事务不提交)，后面的所有对这个表的操作都会被阻塞！
		- 解决方案

			- 避免在有长事务DDL，长事务一直不提交，你的写锁就会阻塞后面的读写，通过查看infomation_schama库中的innodb_trx表看有哪些事务在执行，从来来决定kill掉长事务，或者等待长事务

### 行锁

- 实现层面

	- 存储引擎层
	- innodb 支持行锁，myisam不支持行锁

- 行锁的意义，价值所在

	- 如果没有行锁，对表的修改会上表锁，同一时刻只有一个修改在执行，多个并发修改操作会被阻塞，影响业务的并发度

- 种类

	- 两阶段锁协议

		- 运行机制

			- 在事务中，行锁在需要时加上，事务提交才会释放(并不是用完立刻释放)。

		- 更好的实践

			- 一个事务中如果涉及锁多个行，把最可能造成锁冲突的，最可能影响并发度的尽量往后放(越靠近提交也就意味着锁的时间越短)。

	- 子主题 2

- 死锁

	- 定义

		- 并发系统不同线程出现循环资源依赖，涉及的线程，都在等待其他线程释放资源，这几个线程就会出现无限等待状态，称为死锁。

	- 解决策略

		- 等待超时

			- 实践

				- 设置参数：innodb_lock_wait_timeout（默认为50s）

		- 死锁检测

			- 机制

				- 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。
				- 发起时机：如果要加锁的行上已经有锁并且进入锁等待状态(一个是读锁，来了读锁并不会进入锁等待状态)，就会取判断是否有锁环(a->b->a)

			- 实践

				- 开启死锁检测:innodb_deadlock_detect=on

## 事务

### 解决了什么问题

- 如果事务在可重复读级别，事务T启动的时候会创建一致性视图read-view，之后事务T执行期间，看到的自己启动时候的视图(就像用相机拍了个照，我看到的就是我拍的照，以及我对这个照片的修改)

### 实现原理

- 
- 事务启动的时候向事务系统申请事务ID(唯一并且是按照申请的顺序严格递增)，上图中，V1，V2..各代表一个数据行的版本(并不真实存在，而是根据当前数据和undo log 计算出来的)，U1，U2...代表undo log,这就使得不同数据的版本连接起来了，从而实现，自己只看到自己那个视图
- 实际上，在事务启动时候，生成了->当前活跃事务ID数组(表示还未提交的事务)，如果事务ID不在数组中，那这个事务的修改是可见的，如果事务ID在这个数组中，那么修改是不可见的(通过undo log计算出可见的值)。
- 数据行中有相应的记录数据修改最新版本的 字段trx_id（事务id）
- 更新规则:当事务去更新数据的时候，是先读后写，这个读只能读当前的值(否则数据会覆盖丢失)，被称为当前读。当然select在加锁的时候也可以是当前读(lock in share mode | for uodate)

	- select * from t where id=1 lock in share mode

		- 加了共享锁(S锁)

	- select * from t where id=1 for update

		- 加了拍他锁(X锁)

- 当前读只会读取已经提交的数据(如果一个在当前事务之前来的事务修改了数据还没提交，当前读就会阻塞[因为要加读锁])，所以还是读了已经提交的数据。对于当前事务后来的事务，对数据修改后已经提交，当前事务读到的是已经修改的数据）

### 实践

- 当使用[begin,start transaction]启动一个事务的时候，并不是一个事务起点，而是在执行到第一个操作innodb表的操作时候，才算真正启动。
当然可以通过 start transaction with consistent snapshot ,直接作为事务的起点。

### 视图的概念

- 虚拟表
- innodb实现MVCC时用到的一致性读视图（consistent read view）,用于支持RC(read committed读提交) 和RR（repeatable read 可重复读）的隔离级别实现

### 读提交隔离级别和可重复读的区别

- 可重复读在事务开始时创建快照，然后在整个事务中一直沿用这个视图，而读提交在事务中每执行一个语句就会去计算一个新的视图

	- 对于可重复读，查询只承认在事务启动前就已经提交的数据
	- 对于读提交，查询只承认，在语句启动前就提交的数据

### 并发带来的问题

- 脏读
- 不可重复读
- 读未提交
- 幻读

	- 定义

		- 幻读：在一个事务中，同一个 查询，多次执行，发现结果不一样的情况(幻读仅专指新插入的行)

			- 需要主义，在可重复读隔离级别下，普通的查询是快照读，看不到其他事务插入的数据

	- 幻读带来的问题

		- 语义不一致

			- 情景还原

				- 字段：id.c,d

					- 数据

						- 0，0，0
						- 5，5，5

				- begin; update t set d = 5 where id=0;

					- 子主题 1

		- 数据一致性问题

	- 如何解决幻读问题

		- next-key lock

		  next-key lock是gap lock和row lock的合并，next-key lock只有在隔离级别为:可重复读才会使用。
		  gap lock 间隙锁，左开右闭，(-无穷，maxCount], maxCount是引擎自动生成的

### 事务的隔离级别

- 读已提交
- 可重复读

	- 

### 相关命令

- 隔离级别查询

	- SHOW VARIABLES LIKE 'transaction_isolation'

- 设置隔离级别

	- SET [GLOBAL|SESSION] TRANSACTION ISOLATION LEVEL level;

	  其中level有4种值：
	  level: {
	       REPEATABLE READ
	     | READ COMMITTED
	     | READ UNCOMMITTED
	     | SERIALIZABLE
	  }

- 查询正在执行的事务

	- SELECT * FROM information_schema.INNODB_TRX;

- 查询持有锁的事务

	- SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS

- 查询锁等待的事务

	- SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;

## 脏页面

### mysql为了提高写入速度，更新操作会直接写在内存中，在某些时机写入磁盘，脏页区别于干净页，是指这个数据页是否和磁盘中的一致，一致则是干净页否则是脏页。

### flush时机

- redo log写满了
- 系统内存不足，需要将换出一些脏页腾出空间
- mysql认为系统空闲
- mysql关闭

### flush对性能的影响

- 读性能

	- 一个读要使用大量页面，需要淘汰大量脏页，使得读很慢

- 写性能

	- 页面已满，写会阻塞，写性能瞬间跌到0

### innodb刷脏页策略

- 通过innodb_io_capacity参数告诉数据库，你的磁盘性能，从而让数据库控制刷脏页的速度(如果io能力很低，刷页速度又很快，那么就会应为频繁刷脏页影响数据读写)

## innodb内存管理

### 使用buffer pool管理内存

### buffer pool中的内存页有三种状态：未使用，干净页，脏页

## 表空间的管理

### 空间回收

- 当对数据行进行删除，会将数据行标记为delete这个位置就可以被复用，而没有用的时候，这个地方就形成了一个"空洞"
- 回收方法

	- alter table t engine=innodb（recreate操作）

		- recreate 过程

	- 相关混淆命令

		- analyze table t

			- 只是重建了索引统计

		- optimize table t 

			- recreate+analyze

### 参数

- innodb_file_per_table=[on|off]控制表数据是否单独存在文件中

## count()使用

### count(字段)<count(主键 id)<count(1)≈count(*)

## order by

### 执行过程

- 根据条件查找到数据行，将数据行的返回字段拿出来放入sort buffer，排序返回结果
- 如果mysql认为内存足够大优先使用全字段排序，否则使用rowid排序

### sort buffer

- sort buffer 是用于存放排序数据的内存，如果需要排序的数据<sort_buffer_size,就会直接在内存中排序，否则需要使用磁盘临时文件辅助排序

### 排序方式

- 全字段排序

	- sort buffer中存放所有返回字段，排好后直接返回结果

		- 

- rowid 排序

	- sort buffer中存放rowid 和 排序字段，排完后再次回表取其他返回字段，然后返回

		- 

### 参数

- max_length_for_sort_data

	- 如果要排序的单行数据>设置阈值，采用rowid 排序

- sort_buffer_size

	- 如果需要排序的数据<sort_buffer_size,就会直接在内存中排序，否则需要使用磁盘临时文件辅助排序

## 影响MySQL性能的一些因素

### 短连接风暴

- 连接的建立涉及到建立tcp连接、账号验证、表权限验证。。。，所以连接建立的成本是很高的

### 慢查询性能问题

- 索引设计问题
- 语句使用问题
- mysql选错索引

### QPS突增

## 日志文件的写入

### binlog

- 

	-  write-fsync 规则

### redolog

## MySQL保证主备同步

## 参数

### 连接保持

- wait_timeout:默认值8h

## innodb 取代myisam 的几大原因

### myisam相对于innodb缺了什么

- 不支持事务
- 不支持行锁

## 分支

### mariadb

- 优点

	- mysql的复刻版本，GNU开源协议
	- 并入AliSQL 的alter table  tableName (nowait|wait n)add column 

## 数据内存中的分布

### Innodb buffer pool

- page
- change buffer

